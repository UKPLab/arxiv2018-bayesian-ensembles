% Root file for the contributions of a Decision Making with Multiple Imperfect
% Decision Makers
%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Springer %%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[conference]{IEEEtran}
%\documentclass{sig-alternate-05-2015}
%\documentclass[a4paper]{article}
% \documentclass[12pt,a4paper]{article}

%\usepackage[top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry}
%\usepackage[hmargin=2.9cm,vmargin=2.9cm]{geometry}

%\usepackage{times}
\usepackage{graphicx}
%\usepackage{tabularx}
%\usepackage[toc]{appendix}
%\usepackage{epsfig}

\usepackage[fleqn]{amsmath}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsfonts}
\usepackage{amsthm}

\usepackage{cite}
\usepackage{algorithm2e}
\usepackage{array}
 \usepackage[caption=false,font=footnotesize]{subfig}
% \usepackage{fixltx2e}
 %\usepackage{stfloats}
 \usepackage{url}

\newcommand{\bs}{\boldsymbol}  
\newcommand{\wrtd}{\mathrm{d}}

%\usepackage{booktabs}

\makeatletter
\makeatother %some sort of hack related to the symbol @

% \usepackage{breakcites}
% \usepackage{etoolbox}
% \patchcmd{\@citex}{,}{;}{}{}

\DeclareMathOperator*{\argmax}{\arg\!\max\!} %argmax operator


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{ 
%A Bayesian Method for Vetting and Combining Crowds of Text Annotators
A Bayesian Method for Combining Multiple Unreliable Text Annotators
}

\author{\IEEEauthorblockN{Anonymous}
\IEEEauthorblockA{Anonymous, \\
Anonymous \\
Email: anonymous}
\and
\IEEEauthorblockN{Anonymous}
\IEEEauthorblockA{Anonymous, \\
Anonymous \\
Email: anonymous}
\and
\IEEEauthorblockN{Anonymous}
\IEEEauthorblockA{Anonymous, \\
Anonymous \\
Email: anonymous}
}

\begin{document}

\maketitle

\begin{abstract}
A common task in NLP is sequence labelling, which is performed by both human annotators to 
produce training data and by automatic classifiers that extract information from text.
However, different annotators can often disagree and may have highly varying levels of reliability,
particularly when crowdsourcing is used to annotate spans of text. 
High error rates can be mitigated by combining annotations from multiple annotators,
a technique that is also used by ensembles of classifiers to boost performance.
Existing approaches that model the biases and error rates of annotators have been shown to 
improve over simple heuristics such as majority voting. However, existing methods
ignore the sequential nature of text span annotations and may therefore underperform.
We propose a new Bayesian technique to combined multiple annotators of differing reliability 
and make the software available publicly. 
Using a series of simulations, we show how several different probabilistic
and heuristic approaches perform under different conditions. 
We illustrate how our approach can improve sequential classification performance on a 
real-world argumentation mining task by using it to combine both human annotators and 
an ensemble of automated classifiers.
\end{abstract}

% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{sections/intro}
\input{sections/method}
\input{sections/experiments}
\input{sections/discussion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% use section* for acknowledgment
%\section*{Acknowledgments}

% \addcontentsline{toc}{chapter}{Bibliography}
%\bibliographystyle{apalike}
\bibliographystyle{IEEEtran}
\bibliography{simpson}

\end{document}
