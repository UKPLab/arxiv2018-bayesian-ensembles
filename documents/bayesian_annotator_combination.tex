% Root file for the contributions of a Decision Making with Multiple Imperfect
% Decision Makers
%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Springer %%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[conference]{IEEEtran}
%\documentclass{sig-alternate-05-2015}
%\documentclass[a4paper]{article}
% \documentclass[12pt,a4paper]{article}

%\usepackage[top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry}
%\usepackage[hmargin=2.9cm,vmargin=2.9cm]{geometry}

%\usepackage{times}
\usepackage{graphicx}
%\usepackage{tabularx}
%\usepackage[toc]{appendix}
%\usepackage{epsfig}

\usepackage[fleqn]{amsmath}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsfonts}
\usepackage{amsthm}

\usepackage{cite}
\usepackage{algorithm2e}
\usepackage{array}
 \usepackage[caption=false,font=footnotesize]{subfig}
% \usepackage{fixltx2e}
 %\usepackage{stfloats}
 \usepackage{url}

\newcommand{\bs}{\boldsymbol}  
\newcommand{\wrtd}{\mathrm{d}}

%\usepackage{booktabs}

\makeatletter
\makeatother %some sort of hack related to the symbol @

% \usepackage{breakcites}
% \usepackage{etoolbox}
% \patchcmd{\@citex}{,}{;}{}{}

\DeclareMathOperator*{\argmax}{\arg\!\max\!} %argmax operator


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{ 
%A Bayesian Method for Vetting and Combining Crowds of Text Annotators
A Bayesian Method for Combining Multiple Unreliable Text Annotators

}

\author{\IEEEauthorblockN{Anonymous}
\IEEEauthorblockA{Anonymous, \\
Anonymous \\
Email: anonymous}
\and
\IEEEauthorblockN{Anonymous}
\IEEEauthorblockA{Anonymous, \\
Anonymous \\
Email: anonymous}
\and
\IEEEauthorblockN{Anonymous}
\IEEEauthorblockA{Anonymous, \\
Anonymous \\
Email: anonymous}
}

\begin{document}

\maketitle

\begin{abstract}
VERSION 1:
A common task in NLP is sequence labelling, which is performed by both human annotators to 
produce training data and by automatic classifiers that extract information from text.
However, different annotators can often disagree and may have highly varying levels of reliability,
particularly when crowdsourcing is used to annotate spans of text. 
High error rates can be mitigated by combining annotations from multiple annotators,
a technique that is also used by ensembles of classifiers to boost performance.
Existing approaches that model the biases and error rates of annotators have been shown to 
improve over simple heuristics such as majority voting. However, existing methods
ignore the sequential nature of text span annotations and may therefore underperform.
We propose a new Bayesian technique to combined multiple annotators of differing reliability 
and make the software available publicly. 
Using a series of simulations, we show how several different probabilistic
and heuristic approaches perform under different conditions. 
We illustrate how our approach can improve sequential classification performance on a 
real-world argumentation mining task by using it to combine both human annotators and 
an ensemble of automated classifiers.

VERSION 2:
We present a Bayesian method for combining sequence classifications from multiple annotators with different levels of noise and class bias. Sequential classification is an important problem in fields such as NLP, where many tasks involve annotating spans of text. 
In such tasks, crowdsourcing is often used to obtain training data for automated classifiers. However, individual human annotators have highly variable error rates and different automated classifiers often produce different patterns of errors. In both cases, errors can be reduced by combining multiple annotators.
However, while Bayesian methods have proved effective in combining unreliable classifiers, they have not previously taken into account the sequence of classifications and are therefore unable to incorporate rules that restrict which labels may follow each other, such as with BIO encoding. We propose a new method that incorporates sequence information using hidden Markov models, and show how the priors can be set to capture sequence rules. We analyse performance against established classifier combination methods on synthetic data to show the effects of annotator accuracy, bias and crowd size on performance. We further evaluate the methods on two NLP datasets: crowdsourced annotations of argument components; and predictions of argument components from an ensemble of neural network classifiers. The results show the advantage of modelling sequential dependencies between labels. We make our source code and data available online.

VERSION 3:
Despite sequences being core to NLP, scant work has considered how to handle noisy sequence labels from multiple anno- tators for the same text. Given such anno- tations, we consider two complementary tasks: (1) aggregating sequential crowd la- bels to infer a best single set of consen- sus annotations; and (2) using crowd an- notations as training data for a model that can predict sequences in unannotated text. For aggregation, we propose a novel Hid- den Markov Model variant. To predict se- quences in unannotated text, we propose a neural approach using Long Short Term Memory. We evaluate a suite of meth- ods across two different applications and text genres: Named-Entity Recognition in news articles and Information Extraction from biomedical abstracts. Results show improvement over strong baselines. Our source code and data are available online1. 

VERSION 4:
We present a Bayesian method for combining sequence classifications from multiple annotators with different levels of noise and class bias. Sequential classification is an important problem in fields such as NLP, where many tasks involve annotating spans of text. 
In such tasks, crowdsourcing is often used to obtain training data for automated classifiers. However, individual human annotators have highly variable error rates and different automated classifiers often produce different patterns of errors. In both cases, errors can be reduced by combining multiple annotators.
However, while Bayesian methods have proved effective in combining unreliable classifiers, they have not previously taken into account the sequence of classifications and are therefore unable to incorporate rules that restrict which labels may follow each other, such as with BIO encoding. We propose a new method that incorporates sequence information using hidden Markov models, and show how the priors can be set to capture sequence rules. We analyse performance against established classifier combination methods on synthetic data to show the effects of annotator accuracy, bias and crowd size on performance. We further evaluate the methods on two NLP datasets: crowdsourced annotations of argument components; and predictions of argument components from an ensemble of neural network classifiers. The results show the advantage of modelling sequential dependencies between labels. We make our source code and data available online.

Bayesian classifier combination methods can be used both to obtain reliable classifications from crowdsourced annotations and to combine an ensemble of automated classifiers to reduce overall error rates. 
\end{abstract}

% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{sections/intro}
\input{sections/method}
\input{sections/experiments}
\input{sections/discussion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% use section* for acknowledgment
%\section*{Acknowledgments}

% \addcontentsline{toc}{chapter}{Bibliography}
%\bibliographystyle{apalike}
\bibliographystyle{IEEEtran}
\bibliography{simpson}

\end{document}
