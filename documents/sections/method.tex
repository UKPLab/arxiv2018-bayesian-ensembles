\section{Modelling Text Span Annotations}\label{sec:model}

We model annotations using the IOB schema, in which each token in a document is labelled as either I (in), O (out), or B (begin). The IOB schema requires that the label I cannot directly follow a label O, since a B token must precede the first I in any span. The IOB schema allows us to identify whether a token forms part of an annotation or not, and the use of the B label enables us to separate annotations when one annotation span begins immediately after another without any gap. This schema does not permit overlapping annotations, which are typically undesirable in crowdsourcing tasks where the crowd is instructed to provide one type of annotation. The schema also does not consider different types of annotation, although it is trivial to extend both the schema and our model to permit this case. Using a single model for different types of annotation may be desirable if the annotators are likely to have consistent confusion patterns betweeen different annotation types. 

We propose an extension of the independent Bayesian classifier combination (IBCC) 
model~\cite{kim2012bayesian} for combining annotations provided by a crowd of unreliable annotators. We refer to our model as Bayesian annotator combination or BAC. In BAC, we model the text annotation task as a sequential classification problem, where the true class, $t_i$, of token $i$ may be I, O, or B, and is dependent on the class of the previous token, $t_{i-1}$. This dependency is modelled by a transition matrix, $A$, as used in a hidden markov model. Rows of the transition matrix correspond to the class of the previous token, $t_{i-1}$, while columns correspond to values of $t_i$. Each row is therefore a categorical distribution. 

We model the annotators using a confusion matrix similar to that used in \cite{simpsonlong}, which captures the likelihood that annotator $k$ labels token $i$ with class $c_i^{(k)}$, given the true class label, $t_i$, and the previous annotation from $k$, $c_{i-1}^{(k)}$. The dependency between $c_i^{(k)}$ and $t_i$ allows us to infer the ground truth from noisy or biased crowdsourced annotations. There is also a dependency on the previous worker annotation, since these are constrained in a similar way to the true labels, i.e. the class I cannot follow immediately from class O. Furthermore, mistakes in the class labels are likely to be correlated across several neighbouring tokens, since annotations cover continuous
spans of text. The confusion matrix, $\bs\pi^{(k)}$, is therefore expanded in our model to a three dimensional transition-confusion mtrax, where the element $\pi_{j,l,m}^{(k)} = p(c_i^{(k)} = m | c_{i-1}^{(k)}=l, t_i=j)$. Within $\bs\pi^{(k)}$, the vector $\bs\pi_{j,l}^{(k)} = \{ \pi_{j,l,1}^{(k)},...,\pi_{j,l,L}^{(k)}\} $, where $L$ is the number of class labels, represents a categorical distribution over the worker's annotations conditioned on the ground truth and their previous annotation.

\subsection{Generative Model}

In the BAC approach, the model described above is given a Bayesian treatment by placing prior distributions over the state transition matrix $A$ and worker confusion matrices $\bs\pi^{(k)}$. The generative process is as follows. 

\textbf{Ground truth:} For each class label $j=\{I, O, B\}$, we draw a row of the transition matrix, $A_j \sim \mathrm{Dir}(\bs\beta_j)$, where $\mathrm{Dir}$ is the Dirichlet distribution. 
%We also draw an initial state distribution, $\bs\kappa=\{\kappa_1, ..., \kappa_L\} \sim \mathrm{Dir}(\bs
%\nu)$, where $\kappa_j=p(t_1=j)$. 
For each document $i$ in a set of $N$ documents, we now draw a sequence of class labels $\bs t_i = [t_{i,1}, ..., t_{i, T_i}]$ of length $T_i$. For $\tau=1$, we draw the first label in each sequence from 
$t_{i,\tau} \sim \mathrm{Categorical}(\bs A_{O})$, 
%$t_{i,\tau} \sim \mathrm{Categorical}(\bs \kappa)$, 
then for $\tau > 1$, we draw subsequent labels from $t_{i,\tau} \sim \mathrm{Categorical}(\bs A_{t_{i,\tau-1}})$. The first label in each sequence uses hyperparameters $\bs A_{O}$ because there is no previous annotation, so we assume that the state $t_{i,0}$ prior to the document start is not part of an annotation, and therefore $t_{i,0}=O$ is an outside or $O$ token. 

\textbf{Worker annotations:} For each worker $k\in\{1,...,K\}$, true label $j\in\{1,...,L\}$, and previous worker label $l=\{1,...,L\}$, we draw vectors $\bs\pi_{j,l}^{(k)} \sim \mathrm{Dir}(\bs\alpha^{(k)}_{j,l})$, which make up the three-dimensional transition-confusion matrix. We now draw annotations for each worker $k$ for each document $i$, starting with the first term, $c_{i,1}^{(k)} \sim \mathrm{Categorical}( \bs\alpha^{(k)}_{t_{i,1}, O} )$, then subsequent terms $c_{i,\tau}^{(k)} \sim \mathrm{Categorical}( \bs\alpha^{(k)}_{t_{i,\tau}, c_{i,\tau-1}^{(k)}} )$. As with the true labels, the first annotation in each sequence uses hyperparameters $\bs\alpha^{(k)}_{t_{i,1}, O}$ because we assume that the annotation prior to token $1$ is equivalent to an $O$ annotation. 

\subsection{Variational Bayes (VB) Algorithm}

We modify the mean-field variational Bayes algorithm proposed by \cite{simpsonlong}, 
which assumes an approximate posterior distribution that factorises between the parameters and 
latent variables. For our proposed model, the variational approximation is given by:
\begin{equation}
  q(\bs t, \bs A, \bs\pi^{(1)},...,\bs\pi^{(K)}) = q(\bs t)\prod_{j=1}^L \left\{ q(\bs A_j)\prod_{l=1}^L \prod_{k=1}^K  q(\bs\pi_{j,l}^{(k)}) \right\}
\end{equation}
Below, we summarise the algorithm used to optimise this distribution to obtain an approximate posterior.
We then define the variational factors and expectation terms needed to perform each step of the algorithm. The procedure is as follows:
\begin{enumerate}
 \item \label{step:1} Initialise variational factors for parameters
$\bs A_j$, $\forall j$ and
$\bs\pi_{j,l}^{(k)}, \forall j, \forall l, \forall k$, e.g. by setting to prior distributions.
 \item \label{step:2} Calculate $\mathbb{E}\left[\log \bs A \right]$ 
and $\mathbb{E}\left[\log\bs\pi^{(k)} \right], \forall k$ given the current factors 
$q(\bs A_j)$ and $q(\bs\pi_j^{(k)})$.
 \item Update the variational factor for the ground truth labels, $q(\bs t)$, given 
the expectations $\mathbb{E}\left[\log\bs\pi^{(k)} \right], \forall k$, and
$\mathbb{E}\left[\log \bs A \right]$, using the forward-backward
algorithm\cite{ghahramani2001introduction}, which will be explained further below.
 \item Update the variational factors $q(\bs\pi_j^{(s)}), \forall j, \forall s$ for the confusion matrices given current estimate for $q(\bs t)$.
 \item \label{step:4} Update the variational factor for the transition matrix rows
$q(\bs A_j), \forall j$ given the current estimate for $q(\bs t)$.
 \item \label{step:6} Check for convergence in the ground truth label predictions,
$\mathbb{E}\left[\bs t\right]$, or in the variational lower bound. 
The latter may be more expensive to compute but gives stronger guarantees of convergence. 
If not converged, repeat from step \ref{step:2}.
\item \label{step:7} Output the predictions for the true labels, $\mathbb{E}\left[\bs t\right]$ given the converged estimates of the variational factors.
\end{enumerate}

\subsection{Variational Factors}

Steps 1 to 5 of the algorithm above initialise then iteratively update each variational factor in turn. Each update increases the lower bound on the model evidence by optimising one variational factor given the current estimates of the others. In this section we first provide equations for computing the variational factors, then show how to initialise them and compute the expectation terms required by the algorithm.

For the true labels, $\bs t$, the optimal variational factor is:
%\log\pi^{(k)}_{t_{i,\tau},c^{(k)}_{i,\tau-1},c^{(k)}_{i,\tau}}
\begin{align}
  \log q^*(\bs t) = \mathbb{E}_{q} \left[ \sum_{i=1}^N \sum_{\tau=1}^{T_i} \bigg\{ \log p(t_{i,\tau} | t_{i,\tau-1}, \bs A ) \right. \nonumber \\
  \left. + \sum_{k=1}^K p(c_{i,\tau}^{(k)} | t_{i,\tau}, c_{i,\tau-1}^{(k)}, \bs\pi^{(k)})
  \bigg\} \right] + \mathrm{const}, \nonumber\\
   \label{eq:qstar_t}
   =  \sum_{i=1}^N \sum_{\tau=1}^{T_i} q^*(t_{i,\tau}), \\
 %\log p(t_{i,\tau} | t_{i,\tau-1}, \bs A, \bs c) 
 q^*(t_{i,\tau}) = \sum_{j=1}^L \mathbb{E}_q[p(t_{i,\tau-1}=j | \bs c_{i,1:\tau})] 
 \log A_{j,t_{i,\tau}} \nonumber\\ 
 %\sum_{j'=1}^L p(t_{i,\tau}=j') % \sum_{i=1}^N \sum_{\tau=1}^{T_i}
   \sum_{k=1}^K \log\pi^{(k)}_{t_{i,\tau},c^{(k)}_{i,\tau-1},c^{(k)}_{i,\tau}}
   +  p(\bs c_{i,\tau+1:T_i} | t_{i,\tau}) + \mathrm{const}, \nonumber\\
\end{align}
where...

. The dependency on the previous true label and the subsequent label can be solved using the forward-backward algorithm.  

For convenience, we define the variational posterior for each token as $r_{i,\tau,j} = \mathbb{E}_q[p(t_{i,\tau}=j | \bs c)]$.

The updated variational factor for each vector in the three-dimensional worker transition-confusion matrices is:
\begin{align}
  \log q^*(\bs\pi_{j,l}^{(k)}) = \sum_{m=1}^J N_{j,l,m}^{(k)}\log\pi_{j,l,m}^{(k)} + \log p(\bs\pi_{j,l}^{(k)} | \alpha_{j,l}^{(k)}) + \mathrm{const},
\end{align}
where $N^{(k)}_{j,l,m} = \sum_{i=1}^N\sum_{\tau=1}^{T_i} r_{i,\tau,j} \delta_{m,c^{(k)}_{i,\tau}}$ are
pseudo-counts and $\delta$ is the Kronecker delta. Since we assumed Dirichlet priors, the variational 
factor is also a Dirichlet distribution with parameters $\bs a_{j,l}^{(k)} = \bs\alpha_{j,l}^{(k)} + \bs N_{j}^{(k)}$, where $\bs N_j^{(k)}=\left\{ N_{j,l,m}^{(k)}, \forall m \right\}$. 

Equation \ref{eq:qstar_t} makes use of a three-dimensional matrix term $\mathbb{E}[\log \pi^{(k)}]$, which is computed in step 2
of the VB algorithm summarised above. Each element of this matrix is computed using the following:
\begin{align}
  \mathbb{E}[\log \pi_{j,l,m}^{(k)}] = \Psi(a^{(k)}_{j,l,m}) - \Psi(\sum_{m=1}^L a^{(k)}_{j,l} ),
\end{align}
where $\Psi$ is the digamma function.

The transition matrix for the ground truth labels has the following variational factors for each of its rows:
\begin{align}
  \log q^*(\bs A_{j}) = \sum_{i=1}^N\sum_{\tau=1}^{T_i} r_{i,\tau-1,j} \sum_{j'=1}^L r_{i,\tau,j'}\log\bs A_{j,j'} \nonumber\\
  + \log p(\bs A_j | \bs\beta_j) + \mathrm{const} \nonumber\\
  = \sum_{j'=1}^L N_{j,j'}\log\bs A_{j,j'} 
  + \log p(\bs A_j | \bs\beta_j) + \mathrm{const},
\end{align}
where $N_{j,j'} = \sum_{i=1}^N \sum_{\tau=1}^{T_i} r_{i,\tau-1,j}r_{i,\tau,j'}$ are pseudo-counts of the 
number of times that class $j$ follows class $j'$. The variational factor for $\bs A_j$ is Dirichlet distribution with parameters $\bs b_j = \bs\beta_j + \bs N_{j}$, where $\bs N_{j} = \left\{ N_{j,j'} , \forall j' \right\}$.

For Equation \ref{eq:qstar_t} we also require a term $\mathbb{E}[\log A]$ that is computed in step 2
of the VB algorithm. Using the variational Dirichlet distribution over $\bs A$, we can compute each element as:
\begin{align}
  \mathbb{E}[\log A_{j,j'}] = \Psi(b_{j,j'}) - \Psi(\sum_{j'=1}^L b_{j,j'} ).
\end{align}


\section{Alternative Methods}\label{sec:alt}

To date, a number of methods have been used to reduce annotations from multiple workers to a single gold-standard set. These approaches make use of both heuristic and statistical techniques. This section outlines commonly-used baselines and state-of-the-art methods that we later compare against our method.

\subsection{Majority/Plurality Voting}

For classifications, a simple heuristic is to take the majority label, or for multi-class problems, the most popular label. Examples for NLP classification problems include sentiment analysis\cite{sayeed2011crowdsourcing},.... With text spans, we can use the IOB classes and choose the most popular label for each word, but there are a number of cases where the resulting spans would not follow the constraints of the schema, and an additional step is required to resolve these issues. The problems occur when annotators disagree about the starting and ending points of an annotation:
\begin{itemize}
  \item The votes for a token being inside a span can be split between the classes I and B, which could lead to tokens being excluded from spans even when most have marked them as inside. 
  \item The voting process can lead to spans of I tokens with no preceding B token if there is only a minority of annotators who marked did not agree on the first token. 
  \item The spans from different annotators could partly overlap, causing the overlap area itself to be marked as a separate span. In some cases, this may be a valid annotation, while in others it would be obvious to anyone reviewing the annotation that it is an artefact of the aggregation method. There does not seem to be a simple fix here, except for requesting more annotations from other workers. With a sufficient number of annotations, we expect the problem to be resolved.
\end{itemize}
In our experiments, we define a baseline \emph{majority voting} method, which addresses the problems described above as follows. We resolve the first problem using a two-stage voting process. First, we combine the I and B votes and determine whether each token should be labelled as O or not. Then, for each token marked as I or B, we and perform another voting step to determine the correct label. This resolves cases where annotators disagree about whether a span should be split into two annotations. To resolve the second problem of aggregated spans without a B token at the start, we mark the first I token in any aggregate span as B.  

The voting procedure outlined above produces annotations where the annotations of at least 50\% of workers intersect. A stricter approach can be used, which requires that all the annotators mark a token for it to be included (e.g. \cite{farra2015annotating}). We refer to this approach as the \emph{intersect} method. For tasks where workers are likely to miss many spans, it is also possible to lower the threshold so that we do not require a majority of workers to mark a token as I/B before we accept it as such during aggregation.

\subsection{Worker Accuracy-Based Methods}

Determine worker accuracy from a number of gold-standard tasks. Weight the workers' votes by accuracy and apply the majority voting approach above to produce a \emph{weighted majority voting} method.

An interesting approach is used by \cite{hsueh2009data} that takes into account amibiguity in sentiment classifications. It is unclear whether this can be generalised to other types of annotation such as argument components. 

The weights can also be obtained using unsupervised and semi-supervised learning. In this case we use an EM algorithm, in which we initialise the true annotations using the majority voting method, then use these to compute worker accuracies. The true annotations are then re-estimated using a weighted majority vote. The process repeats until convergence. This method is labelled \emph{weighted majority voting (EM)}. 

\subsection{Clustering Methods}

Cluster the annotations, e.g. using a mixture model with annotation centre and spread, or by merging the boundaries somehow. See Zooniverse annotation work -- could discretize this?

\subsection{Other Solutions}

The level of disagreement in annotations for a particular piece of text can be used to determine whether an annotation is of a insufficient quality to keep (e.g. \cite{sayeed2011crowdsourcing,hsueh2009data}. This can be achieved using the majority voting method, but adjusting the threshold for classifying a token as I/B from 50\% to something higher. 

\emph{Human resolution}: an additional worker selects the correct answer from the annotations provided by the initial set of workers, e.g. \cite{dagan2016specifying}. To reduce costs, the human resolution step could be applied only to text with large amounts of disagreement.

