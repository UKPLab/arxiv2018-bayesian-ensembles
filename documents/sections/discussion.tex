\section{Conclusions}

Previous work has demonstrated the benefits of modeling annotator reliability when aggregating noisy data, 
such as crowdsourced labels. 
We proposed BSC-Seq, a fully Bayesian approach to aggregating sequence labels, 
that models the effect of label sequences on annotator reliability,
and showed how it improves the state-of-the-art, particularly with small datasets.
%To enable more efficient training data collection,
To further improve the quality of aggregated labels,
we designed a variational wrapper for integrating existing black-box 
sequence taggers, such as deep neural networks.
Our results show that this technique can improve aggregated data quality
on both active and passive learning tasks.
%We also found that including a simple conditional independence model of text features enables us to learn BSC-seq more effectively.

Future work will evaluate integrating sequence taggers that use
Bayesian methods for deep learning, 
which may improve active learning.
We will also investigate
alternative data selection strategies to bootstrap active learning, 
and how to set priors for %reduce over-confidence in predictions by including
the reliability of black-box methods by experimenting
on other training sets of similar size.

%how to adapt hyper-parameters of the NN automatically in low-resource state?

% % In future, BSC-Seq could be applied to other sequential classification tasks beside span annotation.
% For example, the order of tasks that are intended to be exchangeable may affect the likelihood
% of the labels provided by the annotators\cite{mathur2017}. Seq-BCC could be applied to model the 
% propensity of the workers to choose certain labels given their previous labels, while the 
% ground truth sequence may be ignored.
