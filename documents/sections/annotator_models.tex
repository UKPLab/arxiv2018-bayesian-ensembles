\section{ Modeling Sequential Annotators }\label{sec:annomodels}

When combining multiple annotators with varying skill levels, we can improve performance by modeling their individual reliability. Several models have previously been applied that do not consider dependencies between a sequence of annotations. In this section, we describe these existing models and provide an extension that captures sequential dependencies. Each of the approaches presented employs a particular function, $A$, to model the likelihood of the annotator choosing the label $c_{\tau}$
given the true label, $t_{\tau}$, for token $\tau$.

\textbf{Accuracy model (acc)}: simply models the annotator's accuracy, $\pi$, as follows: 
\begin{flalign}
 & A = p( c_{\tau} \! = \! i | t_{\tau} \! = \! j, \pi ) = \left.
\begin{cases}
  \pi  \!&\!\!\!\text{ where } i = j \\
  \frac{1 - \pi}{J-1} \!&\!\!\!\text{ otherwise}
\end{cases} 
\right\} \!, &&
\end{flalign}
where $c_{\tau}$ is the label given by the annotator for token $\tau$, $t_{\tau}$ is its true label
and $J$ is the number of classes.
This is the basis of several previous methods~\cite{donmez2010probabilistic,rodrigues2013learning}. 
The limitation of this approach is that it assumes reliability is constant,
which means that in domains where one class label is far more common than others, 
a spammer who always selects the most common label will nonetheless 
have a high $\pi$.
%despite their labels being uninformative.
%Annotator models define a likelihood... 
%\begin{flalign}
%& A = p(c_{\tau}, c_{\tau-1}, t_{\tau}) = p( c_{\tau} \!\!=\! i | c_{\tau-1}, t_{\tau} \!=\! j, \bs\pi ),&&
%\end{flalign}

\textbf{MACE spamming model}~\cite{hovy2013learning}:
This method again assumes a constant annotator accuracy, $\pi$,
but also models the case where annotators are incorrect by assuming they label according to 
a spamming distribution, $\bs\xi$, that is independent of the true label, $t_{\tau}$.
\begin{flalign}
A & = p( c_{\tau} = i | t_{\tau} = j, \pi, \bs\xi) && \nonumber \\
& = \left.
\begin{cases}
  \pi + (1 - \pi) \xi_j  &\text{ where } i = j \\
  (1 - \pi) \xi_j &\text{ otherwise}
\end{cases} 
\right\}.
\end{flalign}
While MACE can capture spamming patterns, it does not explicitly model 
different rates of errors per class. This could be an issue for sequence tagging using the 
BIO encoding, for example, if an annotator frequently labels longer spans
 than the true spans by starting the spans one or two tokens early. In this 
 case, they may more frequently
mis-label the `B' tokens than the `I' or `O' tokens,  but this cannot be modeled by MACE. 

\textbf{Confusion vector (CV)}: this approach learns a separate accuracy 
 for each class label~\cite{nguyen2017aggregating}
using a parameter vector, $\bs\pi$, of size $J$:
\begin{flalign}
& A = p( c_{\tau} \!\!=\! i | t_{\tau} \!=\! j, \bs\pi ) = \left.
\begin{cases}
  \pi_j  \!\!\!\!\!\!&\text{ where } i \!=\! j \\
  \frac{1 \!- \!\pi_j}{J-1} \!\!\!\!\!\!&\text{ otherwise}
\end{cases} 
\! \right\} \!.&&
\end{flalign}
For the incorrect label cases where $i \! \neq \! j$,
 $p( c_{\tau} \!\!=\! i | t_{\tau} \!=\! j, \bs\pi )$ is constant for all values of $i$.
 Therefore, this model does not explicitly capture spamming
patterns where one of the incorrect labels has a much higher likelihood than the others.

\textbf{Confusion matrix (CM)}~\cite{dawid_maximum_1979}:
this model can be seen as an expansion of the confusion vector so that $\bs\pi$ becomes a 
$JxJ$ matrix with values given by:
\begin{flalign}
& A = p( c_{\tau} \!\!=\! i | t_{\tau} \!=\! j, \bs\pi ) = 
  \pi_{j,i} .&&
\end{flalign}
This requires a larger number of parameters, $J^2$, compared to the $J+1$ parameters of MACE or $J$ parameters
of the confusion vector.
The confusion matrix therefore represents the probability of each individual mistake,
so it can model spammers who frequently chose one label regardless
of the ground truth.
It can also model annotators in sequence tagging tasks who have different error rates for `B-x', `I-x' and `O' labels, for example, if an annotator is better at detecting type `x' spans than type `y', or if they frequently mis-label the start of a span as `O' when the true label is `B-x', but are otherwise accurate.
However, the confusion matrix ignores the dependencies between annotations in a sequence that affect these probabilities.
For instance, it is usually not possible for an annotator to assign an `I' label that is preceded by `O'.
% Consider the following example where this may be a problem: three annotators produce sequences of labels as follows:
% O-B-I-I-I-O
% O-O-B-I-O-O
% O-O-O-O-O-O
% We can see that the first two annotators agree that the third token is part of the span, 

\textbf{Sequential Confusion Matrix (seq)}: we introduce a new extension to the confusion matrix to model the dependency 
of each label in a sequence on its predecessor. The likelihood of a label can now be written as follows:
\begin{flalign}
& A = p( c_{\tau} \!\!=\! i | c_{\tau-1} \!=\! \iota, t_{\tau} \!=\! j, \bs\pi ) = 
  \pi_{j,\iota,i} ,&&
\end{flalign}
where $\bs\pi$ is now three-dimensional with size $J\times J\times J$.
In the case of disallowed transitions, e.g. from $c_{\tau-1}=$`O' to $c_{\tau}=$`I', the value $\pi_{j,c_{\tau-1},c_{\tau}}=0$, $\forall j$
does not need to be learned. 
The sequential model can capture phenomena such as a tendency toward overly long sequences, by learning that
$\pi_{O,O,O} > \pi_{O,I,O}$,
or a tendency to split spans by inserting `B' in place of `I' by increasing the value of
$\pi_{I,I,B}$ without affecting $\pi_{I,B,B}$ and $\pi_{I,O,B}$.

The annotator models described above are extensions of one another that can be used as part of the model for aggregating sequential annotations described in the next section. 
The experiments in Section \ref{sec:expts_all} 
 test whether the more expressive seq annotator model,
which has more parameters to learn, is beneficial in a realistic setting.
