\section{ Modeling Sequential Annotators }\label{sec:annomodels}

When combining multiple annotators with varying skill levels, we can improve performance by modeling their individual reliability. Here, we describe several existing models 
that do not consider dependencies between annotations in a sequence,
then provide an extension that captures sequential dependencies. Each of the approaches presented employs a particular function, $A$, to model the likelihood of the annotator choosing the label $c_{\tau}$
given the true label, $t_{\tau}$, for token $\tau$.

\textbf{Accuracy model (acc)}: simply models the annotator's accuracy, $\pi$, as follows: 
\begin{flalign}
 & A = p( c_{\tau} \! = \! i | t_{\tau} \! = \! j, \pi ) = \left.
\begin{cases}
  \pi  \!&\!\!\!\text{ where } i = j \\
  \frac{1 - \pi}{J-1} \!&\!\!\!\text{ otherwise}
\end{cases} 
\right\} \!, &&
\end{flalign}
where $c_{\tau}$ is the label given by the annotator for token $\tau$, $t_{\tau}$ is its true label
and $J$ is the number of classes.
This is the basis of several previous methods~\cite{donmez2010probabilistic,rodrigues2013learning}. 
%The limitation of this approach is that it
It assumes reliability is constant,
which means that when one class label is far more common than others, 
a spammer who always selects the most common label will nonetheless 
have a high $\pi$.
%despite their labels being uninformative.
%Annotator models define a likelihood... 
%\begin{flalign}
%& A = p(c_{\tau}, c_{\tau-1}, t_{\tau}) = p( c_{\tau} \!\!=\! i | c_{\tau-1}, t_{\tau} \!=\! j, \bs\pi ),&&
%\end{flalign}

\textbf{MACE spamming model}~\cite{hovy2013learning}:
assumes a constant annotator accuracy, $\pi$,
but that when annotators are incorrect, they label according to 
a spamming distribution, $\bs\xi$, that is independent of the true label, $t_{\tau}$.
\begin{flalign}
A & = p( c_{\tau} = i | t_{\tau} = j, \pi, \bs\xi) && \nonumber \\
& = \left.
\begin{cases}
  \pi + (1 - \pi) \xi_j  &\text{ where } i = j \\
  (1 - \pi) \xi_j &\text{ otherwise}
\end{cases} 
\right\}.
\end{flalign}
This addresses the case where spammers choose the most common label when the classes are imbalanced.
While MACE can capture spamming patterns, it does not explicitly model 
different rates of errors per class. This could be an issue for sequence tagging using the 
BIO encoding, for example, if an annotator frequently labels longer spans
 than the true spans by starting the spans early. In this 
 case, they may more frequently
mis-label the `B' tokens than the `I' or `O' tokens,  which cannot be modeled by MACE. 

\textbf{Confusion vector (CV)}: this approach learns a separate accuracy 
 for each class label~\cite{nguyen2017aggregating}
using parameter vector, $\bs\pi$, of size $J$:
\begin{flalign}
& A = p( c_{\tau} \!\!=\! i | t_{\tau} \!=\! j, \bs\pi ) = \left.
\begin{cases}
  \pi_j  \!\!\!\!\!\!&\text{ where } i \!=\! j \\
  \frac{1 \!- \!\pi_j}{J-1} \!\!\!\!\!\!&\text{ otherwise}
\end{cases} 
\! \right\} \!.&&
\end{flalign}
%For the incorrect label cases where $i \! \neq \! j$,
% $p( c_{\tau} \!\!=\! i | t_{\tau} \!=\! j, \bs\pi )$ is constant for all values of $i$.
% Therefore, t
This model does not explicitly capture spamming
patterns where one of the incorrect labels has a much higher likelihood than the others.

\textbf{Confusion matrix (CM)}~\cite{dawid_maximum_1979}:
this model can be seen as an expansion of the confusion vector so that $\bs\pi$ becomes a 
$J\times J$ matrix with values given by:
\begin{flalign}
& A = p( c_{\tau} \!\!=\! i | t_{\tau} \!=\! j, \bs\pi ) = 
  \pi_{j,i} .&&
\end{flalign}
This requires a larger number of parameters, $J^2$, compared to the $J+1$ parameters of MACE or $J$ parameters
of the confusion vector.
CM %represents the probability of each mistake, so it 
can model spammers who frequently chose one label regardless
of the ground truth, 
as well as annotators in sequence tagging tasks with different error rates for `B-x', `I-x' and `O' labels.
For example, if an annotator is better at detecting type `x' spans than type `y', or if they frequently mis-label the start of a span as `O' when the true label is `B-x', but are otherwise accurate.
However, the confusion matrix ignores dependencies between annotations in a sequence, % that affect these probabilities.
such as the fact that an `I' cannot immediately follow an `O'.
% Consider the following example where this may be a problem: three annotators produce sequences of labels as follows:
% O-B-I-I-I-O
% O-O-B-I-O-O
% O-O-O-O-O-O
% We can see that the first two annotators agree that the third token is part of the span, 

\textbf{Sequential Confusion Matrix (seq)}: we introduce a new extension to the confusion matrix to model the dependency 
of each label in a sequence on its predecessor,
giving the following likelihood:
\begin{flalign}
& A = p( c_{\tau} \!\!=\! i | c_{\tau-1} \!=\! \iota, t_{\tau} \!=\! j, \bs\pi ) = 
  \pi_{j,\iota,i} ,&&
\end{flalign}
where $\bs\pi$ is now three-dimensional with size $J\times J\times J$.
In the case of disallowed transitions, e.g. from $c_{\tau-1}=$`O' to $c_{\tau}=$`I', the value $\pi_{j,c_{\tau-1},c_{\tau}}=0$, $\forall j$
is fixed \textit{a priori}. 
The sequential model can capture phenomena such as a tendency toward overly long sequences, by learning that
$\pi_{O,O,O} > \pi_{O,I,O}$,
or a tendency to split spans by inserting `B' in place of `I' by increasing the value of
$\pi_{I,I,B}$ without affecting $\pi_{I,B,B}$ and $\pi_{I,O,B}$.

Many commonly-used annotator models can therefore be seen as extensions of one another.
The next section shows how these models can be used as part of 
a model for aggregating sequential annotations. 
The experiments in Section \ref{sec:expts_all} 
 test whether the more expressive seq annotator model,
which has more parameters to learn, is beneficial in a realistic setting.
