Type,Count,Reason?,Resolution
"split in two or more, should only identify one part",15,"p(O | B, c-=O) is higher in BAC than p(O | B ) in IBCC, which is equivalent to combining p(O | B, c-=O) with p(O | B, c-=I) (low value) and p(O | B, c-=B) (very low value). Split can occur where there is no B label given because some annotations are too long -- p(O | B, c-=I) and p(I | B, c-=I) are too high? Some cases the annotation is not split but is just too long: p( B | I, C-=O) must be high too."," We want the first half to be marked as O | there is a later token where all labellers provide B or I. This would be propagated through p(t | t-), i.e p(t=B | t-=O ) > p(t=B | t-=I). P(missing) too high with BAC if previous label was O -- could avoid by increasing overall accuracy bias in prior? More data may not help (unless training data) because the imbalance between transitions would still persist. "
span only marked by one or two annotators,16,"p(O | B, c-=O) is too high?",emphasise prior accuracy bias?
"split in two or more, should identify all parts as one",1,"Common transitions such as I-I and O-O mean that the later token carries little weight, whereas unusual annotator transitions such as I-B are stuck close to priors and therefore the model could favour annotators with unusual transitions. ",The simplified model may help because the confusion matrix would be more accurately learned for the rare transitions.
doesn't split when it should -- annotation covers gap,3,"p(O | I, c-=O) is too high?",emphasise prior accuracy bias?
,,,"Where does the bias toward believing B labels come from? Is it possible that the priors pseudocounts in each row are not the same because some transitions are set from 1 to 0? Could this create a bias toward believing class I? In this case, we can remove the strong diagonals from the | c-=I transition"